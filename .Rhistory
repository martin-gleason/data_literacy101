<<<<<<< HEAD
<<<<<<< HEAD
class: center
# Data or Information
.left[Data:
* Facts, figures, and other abstract representations of the world
+ Height
+ Weight
+ Number of Charges
+ Length of Term of Probation
+ Demographics]
---
class: center
# Data or Information
.left[Information:
* Data that has been processed, given structure, and context
+ Charts and graphs
+ Risk Level
- Credit
- Census
+ Body Mass Index (BMI)
- [Far From Perfect Model](https://www.npr.org/templates/story/story.php?storyId=106268439)]
---
# Data or Information
* Exercise: Revisit the *How do you use data.*
* Reclassify items as "Data or Information"
.center[![](imgs/classification.jpg)]
---
# How much data do we need?
--
* Pros and cons of Personal Experience
--
* Professional/Clinical Judgment
--
+ *Challenging either can be easily interpreted as a personal attack*
--
+ *Why not just collect all the data?*
* **A better question is: What data do we need?**
.center[![](imgs/toomuch.gif)]
???
* Point is to break down the difference between Data and Information
* Encourage the development of data driven culture
---
class: center
# The Language of Data
.pull-left[![:scale 85%](imgs/DataScienceTriangleAnalogy.jpg)]
.pull-right[![:scale 85%](imgs/DataScienceTriangle.jpg)]
##Think of data and information as a new language that requires fluency
---
# Types of Data
## Quantitative
*  Discrete: only specific values matter for that data
*  Continuous: All values
*  *Examples?*
+ Height
--
+ Weight
--
+ Age
--
+ Income Data
--
+ Blood Pressure
---
# Types of Data
## Qualitative
*  Binary: Yes/No
*  Nominal: Names with no particular meaning
*  Ordinal: Scores or Ranks
*  Count/Ratio: Items per Area/Volume
*  *Examples?*
--
+ Tax Bracket
+ Probation Specific
- Binary
- Ordinal
+ Geographic Location
---
class: center
background-image: url(imgs/coffee.jpg)
background-size: cover;
#The Coffee Example
???
* coffee as discrete, continuous, and categorical(binary) data.
---
class:center
# Descriptive Statistics
>  "Descriptive statistics are brief descriptive coefficients that summarize a given data set, which can be either a representation of the entire or sample population. Descriptive statistics are broken down into measures of central tendency and measures of variability (spread)."
.right[[--Investopedia](https://www.investopedia.com/terms/d/descriptive_statistics.asp)]
---
# Measures of Central Tendency and Variablity
* Mean: Average
--
* Median: Equal point in the distribution
--
* Mode: Most frequent number
--
* Range: Minimum number to maximum number
--
* Variance: How spread out the data points are
--
* Standard Deviation: The distance, in the same unit, between data points
???
* Ask why these are useful measures for us
* point to JDAI stats, detention stats
* dis-aggregating data by race was a huge push for JDAI, what else should we separate?
---
class:center
# Total Height
```{r, TrickQuestion_one, include= TRUE, echo = F, fig.align='center', fig.height = 6, fig.width = 8, message = FALSE}
total_height_bar
```
---
class:center
## Density of Height
```{r, TrickQuestion_two, include= TRUE, fig.align='center', fig.height = 6, fig.width = 8, echo = F}
total_height
```
---
class:center
## Measures of Central Tendency with Height
```{r, trickquestionThree, include = TRUE, echo = FALSE, fig.align='center', fig.height = 6, fig.width = 8, message = FALSE}
bad_proof
```
---
## Chart Example
```{r, badchart, include = TRUE, echo = FALSE, warning = FALSE, fig.align='center', fig.height = 6, fig.width = 6, message = FALSE}
bad_height %>% kable() %>% kable_styling("striped", "bordered", full_width = TRUE)
```
---
## Exercise 2: How did I mislead you?
```{r, side_by_side, include = TRUE, warning = FALSE, out.width="49%", fig.height = 15, fig.width = 15, fig.show = "hold", message = FALSE, echo = FALSE}
total_height + theme(axis.text = element_text(family = "Nobile", size = 48 ),
axis.title = element_text(family = "Nobile", size = 48 ))
total_height_bar + theme(axis.text = element_text(family = "Nobile", size = 48 ),
axis.title = element_text(family = "Nobile", size = 48 ))
```
???
* Lead a discussion about what is wrong with this graph
* point out that it lacks
+ a title
+ no sourcing information
+ units are not clear
+ Bar Graph is not normal
+ clue is in the chart
---
## Correct Way to Visualize
```{r, correct_viz, include = TRUE, echo = FALSE, message = FALSE, fig.align='center', fig.height = 4, fig.width = 10, message = FALSE}
total_height_sex_histogram +
theme(panel.spacing = unit(5, "lines"))+
facet_grid(~ sex)+
theme(axis.text = element_text(family = "Nobile", size = 20 ),
axis.title = element_text(family = "Nobile", size = 20 ),
legend.text = element_text(family = "Nobile", size = 20),
legend.title = element_text(family = "Nobile", size = 20))
total_height_chart %>% kable(caption = "All Measurements in cm") %>%
kable_styling("striped", "bordered", full_width = FALSE)
```
???
* ask if there are other questions or points to this graph
* point to the scales as another aspect to be critical of
---
# The Stastical Model
* A representation of what the data tells us
* The goal of:
+ Big Data
+ Machine Learning
+ AI
--
.center[![:scale 53%](imgs/boosting-algo-7.gif)]
???
Actuarial vs Statistical model discussion can occur.
---
# Four Kinds of Analytics
* Descriptive: What?
+ Very similar to descriptive statistics.
* Diagnostic: Why?
* Predictive: What if?
* Prescriptive: Best course?
---
## Diagnostic Analytics
.center[![Do not be afraid to ask why.](imgs/why.gif)]
* Why did this happen?
---
## Predictive Analytics
* What could happen
+ Chances of winning an election
+ Chances of developing an illness
+ Chance at re-offending
--
.center[![:scale 60%](imgs/superimportantoutcome.png)]
---
# Perscriptive  Analytics
* What is the best course of action?
.center[![The Process](imgs/Prescriptive_Analytics_process.png)]
---
## Exercise 3: Discussion of Prescriptive Statistics
--
.center[![:scale 75%](imgs/scrouge.gif)]
---
# How do we collect data or information?
--
* Personal Experiences
* TV
* Newspapers
* Radio
* Conversations
* Comparison shopping
* Google
* Facebook
---
# How does the *Court* collect data?
* Forms
--
* Reports
--
* Studies
--
* JEMS
+ *C5/Supervisor is coming!*
--
* Other Systems
+ I-Clear
+ Clerks
+ State's Attorney
+ Schools
+ Hospital
+ Promise
--
* Databases
--
* *Spreadsheets*
---
.center[# Tidy Data]
* Each variable forms a column.
* Each observation forms a row.
* Each cell is atomic.
* Each type of observational unit forms a table.
--
.center[![Sad Cat](imgs/messy-data-makin-me-sad-.jpg)]
---
.center[# Spreadsheet Use]
* We use spreadsheets for:
+ Collection, cleaning, results, analysis
+ Provide structure to our data
+ Share data/information
+ Data Analysis
* In our office, we use Excel
+ Google Sheets
+ And, occasionally, tables in Word
+ What should we use Spreadsheets for?
---
class: center
# Exercise 4: Critique This Spreadsheet
.center[![:scale 95%](imgs/fakeSheet.png)]
???
* This spreadsheet will be a handout
* Solo work
* 10-15 minutes
* The image will remain on screens
---
# Exercise 4: Takeaways
* Cells are not atomic
* Missing values
* Variable formats within entries
---
# Why Do We Need Data: Takeaways
* Evidence Based Practices
* Performance based budgeting
* Risk Level and Classification
---
# Four Kinds of Analytics: Redux
* Descriptive: What?
* Diagnostic: Why?
* Predictive: What if?
* Prescriptive: Best course?
---
# Where Do We Go From Here
* We have the language, now what are *our* goals?
--
* With your table, discuss where you want to go from here.
--
* Use your SMART goals!
---
# Thank you
.center[![Thank You](imgs/anyQuestionsDavidSPumpkins.gif)]
* Please fill out your evaluation forms
* Email [martin.gleason@cookcountil.gov](mailto: martin.gleason@cookcountil.gov) if you have questions, comments, or vague misgivings
---
# Sources and Further Reading
* [Tidy data Paper](https://vita.had.co.nz/papers/tidy-data.pdf)
* [Data Literacy](https://www.gartner.com/webinar/3702517)
* [Algorithmic Sentencing](https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/)
* [Descriptive, predictive, prescriptive](https://halobi.com/blog/descriptive-predictive-and-prescriptive-analytics-explained/)
* [https://twitter.com/nlj/status/1004066012063559686](https://twitter.com/nlj/status/1004066012063559686)
* [4 kinds of analytics](https://www.kdnuggets.com/2017/07/4-types-data-analytics.html)
* [Super Important Outcome](https://blogs.uoregon.edu/rclub/2016/04/05/plotting-your-logistic-regression-models/)
* [Minitab: Flavors of Data](https://surfstat.anu.edu.au/surfstat-home/1-1-1.html)
* [Statistical Model](https://en.wikipedia.org/wiki/Statistical_model)
* [BMI](https://www.npr.org/templates/story/story.php?storyId=106268439)
* [Coffee Info Graphic](http://www.hammadakbar.com/marketing/content-creation-in-a-slump-here-are-5-ways-qualitative-data-can-help/)
//
library("sysfonts")
remove.packages(c("sysfonts", "showtext"))
install.packages(c("sysfonts", "showtext"))
install.packages(c("sysfonts", "showtext"))
detach(*)
?detach
loadedNamespaces()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
warnings()
?fig.height
#Discretion Mapping Word Cloud
from <- "https://richpauloo.github.io/2017-12-29-Using-tidytext-to-make-word-clouds/"
library("tidytext")
=======
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
bad_proof <- total_height +
geom_area(data = subset(df_height_den, x >= height_quants$q5 & x <= height_quants$q95),
aes(x = x, y = y), fill = "#9b9292") +
geom_vline(aes(xintercept = height_quants$median, color = "Median"), size = 1.5) +
geom_vline(aes(xintercept = mean(height), color = "Mean"), size = 1.5) +
scale_color_manual(name = "Descriptive Statistics", values = c(Median = "red", Mean = "#eebf48")) +
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_bar <- height %>% group_by(sex) %>%
ggplot(aes(x = height)) + geom_bar(stat = "count", fill = "#a5d3c1", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_chart <- height %>% group_by(sex) %>%
summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Count" = n(),
"Standard Deviation" = sd(height))
total_height_sex_histogram <- height %>%
group_by(sex) %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram( aes(y = ..density..), col = "black", position = "dodge")+
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite), fill = "Sex")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men <- height %>% filter(sex == "M")
height_women <- height %>% filter(sex == "F")
height_men_hist <- height_men %>%
ggplot(aes(x = height)) + geom_histogram(aes(y = ..density..), fill = "blue", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_men$height), sd(height_men$height)),
col = "blue",
lwd = 1)
height_women_hist <- height_women %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram(aes(y = ..density..), fill = "#990000", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_women_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_women$height), sd(height_women$height)),
col = "black",
lwd = 1) +
labs(y = "Probability Distribution")
prob_57 <- pnorm(57, mean = mean(height_women$height), sd = sd(height_women$height))
prob_164 <- pnorm(164, mean = mean(height_women$height), sd = sd(height_women$height))
height
height <- read_csv(file_location)
height <- height %>% select(-1)
height <- height$height * 2.54
height
height_quants <- height %>% summarise(q5 = quantile(height, .05),
q95 = quantile(height, .95),
avg = mean(height),
median = median(height))
class(height)
height <- as.numeric(height$height * 2.54)
=======
>>>>>>> master
height <- height %>% select(-1)
height <- read_csv(file_location)
height <- height %>% select(-1)
height <- as.numeric(height$height * 2.54)
height_quants <- height %>% summarise(q5 = quantile(height, .05),
q95 = quantile(height, .95),
avg = mean(height),
median = median(height))
height_cm <- read_csv(file_location)
height_cm <- read_csv(file_location)
height <- height_cm %>% select(height)
height <- as.numeric(height$height * 2.54)
height_quants <- height %>% summarise(q5 = quantile(height, .05),
q95 = quantile(height, .95),
avg = mean(height),
median = median(height))
height <- height_cm %>% select(height)
height
height
height <- height * 2.54
View(height)
height <- height_cm %>% select(height)
height <- height * 2.54
height_quants <- height %>% summarise(q5 = quantile(height, .05),
q95 = quantile(height, .95),
avg = mean(height),
median = median(height))
height_quants
library("tidyverse")
#all heights in inches
cite <- "https://vincentarelbundock.github.io/Rdatasets/doc/carData/Davis.html"
#height <- read_csv("/Users/martin.gleason/Dropbox (Personal)/Coding Projects/DataSets/height_weight.csv") #windows version
file_location <- "/Users/marty/Dropbox (Personal)/Coding Projects/DataSets/height_weight.csv"
height_cm <- read_csv(file_location)
height <- height_cm %>% select(height)
height <- height * 2.54
height_quants <- height %>% summarise(q5 = quantile(height, .05),
q95 = quantile(height, .95),
avg = mean(height),
median = median(height))
x.dens <- density(height$height)
df_height_den <- data.frame(x = x.dens$x, y = x.dens$y)
bad_height <- height %>% summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Standard Deviation, in Inches" = sd(height))
total_height <- height %>%
ggplot(aes(x = height)) +
geom_density(fill = "#a5d3c1") +
labs(x = "Height in Inches", y = "Probability Distribution")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
bad_proof <- total_height +
geom_area(data = subset(df_height_den, x >= height_quants$q5 & x <= height_quants$q95),
aes(x = x, y = y), fill = "#9b9292") +
geom_vline(aes(xintercept = height_quants$median, color = "Median"), size = 1.5) +
geom_vline(aes(xintercept = mean(height), color = "Mean"), size = 1.5) +
scale_color_manual(name = "Descriptive Statistics", values = c(Median = "red", Mean = "#eebf48")) +
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_bar <- height %>% group_by(sex) %>%
ggplot(aes(x = height)) + geom_bar(stat = "count", fill = "#a5d3c1", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_chart <- height %>% group_by(sex) %>%
summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Count" = n(),
"Standard Deviation" = sd(height))
total_height_sex_histogram <- height %>%
group_by(sex) %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram( aes(y = ..density..), col = "black", position = "dodge")+
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite), fill = "Sex")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men <- height %>% filter(sex == "M")
height_women <- height %>% filter(sex == "F")
height_men_hist <- height_men %>%
ggplot(aes(x = height)) + geom_histogram(aes(y = ..density..), fill = "blue", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_men$height), sd(height_men$height)),
col = "blue",
lwd = 1)
height_women_hist <- height_women %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram(aes(y = ..density..), fill = "#990000", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_women_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_women$height), sd(height_women$height)),
col = "black",
lwd = 1) +
labs(y = "Probability Distribution")
prob_57 <- pnorm(57, mean = mean(height_women$height), sd = sd(height_women$height))
prob_164 <- pnorm(164, mean = mean(height_women$height), sd = sd(height_women$height))
height <- height_cm %>% select(height, sex)
height <- height$height * 2.54
>>>>>>> master
library("tidyverse")
#all heights in inches
cite <- "https://vincentarelbundock.github.io/Rdatasets/doc/carData/Davis.html"
#height <- read_csv("/Users/martin.gleason/Dropbox (Personal)/Coding Projects/DataSets/height_weight.csv") #windows version
file_location <- "/Users/marty/Dropbox (Personal)/Coding Projects/DataSets/height_weight.csv"
height_cm <- read_csv(file_location)
height <- height_cm %>% select(height, sex)
height <- height$height * 2.54
height_quants <- height %>% summarise(q5 = quantile(height, .05),
q95 = quantile(height, .95),
avg = mean(height),
median = median(height))
x.dens <- density(height$height)
df_height_den <- data.frame(x = x.dens$x, y = x.dens$y)
bad_height <- height %>% summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Standard Deviation, in Inches" = sd(height))
total_height <- height %>%
ggplot(aes(x = height)) +
geom_density(fill = "#a5d3c1") +
labs(x = "Height in Inches", y = "Probability Distribution")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
bad_proof <- total_height +
geom_area(data = subset(df_height_den, x >= height_quants$q5 & x <= height_quants$q95),
aes(x = x, y = y), fill = "#9b9292") +
geom_vline(aes(xintercept = height_quants$median, color = "Median"), size = 1.5) +
geom_vline(aes(xintercept = mean(height), color = "Mean"), size = 1.5) +
scale_color_manual(name = "Descriptive Statistics", values = c(Median = "red", Mean = "#eebf48")) +
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_bar <- height %>% group_by(sex) %>%
ggplot(aes(x = height)) + geom_bar(stat = "count", fill = "#a5d3c1", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_chart <- height %>% group_by(sex) %>%
summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Count" = n(),
"Standard Deviation" = sd(height))
total_height_sex_histogram <- height %>%
group_by(sex) %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram( aes(y = ..density..), col = "black", position = "dodge")+
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite), fill = "Sex")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men <- height %>% filter(sex == "M")
height_women <- height %>% filter(sex == "F")
height_men_hist <- height_men %>%
ggplot(aes(x = height)) + geom_histogram(aes(y = ..density..), fill = "blue", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_men$height), sd(height_men$height)),
col = "blue",
lwd = 1)
height_women_hist <- height_women %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram(aes(y = ..density..), fill = "#990000", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_women_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_women$height), sd(height_women$height)),
col = "black",
lwd = 1) +
labs(y = "Probability Distribution")
prob_57 <- pnorm(57, mean = mean(height_women$height), sd = sd(height_women$height))
prob_164 <- pnorm(164, mean = mean(height_women$height), sd = sd(height_women$height))
height <- height$height * 2.54
height <- height[1] * 2.54
library("tidyverse")
#all heights in inches
cite <- "https://vincentarelbundock.github.io/Rdatasets/doc/carData/Davis.html"
#height <- read_csv("/Users/martin.gleason/Dropbox (Personal)/Coding Projects/DataSets/height_weight.csv") #windows version
file_location <- "/Users/marty/Dropbox (Personal)/Coding Projects/DataSets/height_weight.csv"
height_cm <- read_csv(file_location)
height <- height_cm %>% select(height, sex)
height <- height[1] * 2.54
height_quants <- height %>% summarise(q5 = quantile(height, .05),
q95 = quantile(height, .95),
avg = mean(height),
median = median(height))
x.dens <- density(height$height)
df_height_den <- data.frame(x = x.dens$x, y = x.dens$y)
bad_height <- height %>% summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Standard Deviation, in Inches" = sd(height))
total_height <- height %>%
ggplot(aes(x = height)) +
geom_density(fill = "#a5d3c1") +
labs(x = "Height in Inches", y = "Probability Distribution")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
bad_proof <- total_height +
geom_area(data = subset(df_height_den, x >= height_quants$q5 & x <= height_quants$q95),
aes(x = x, y = y), fill = "#9b9292") +
geom_vline(aes(xintercept = height_quants$median, color = "Median"), size = 1.5) +
geom_vline(aes(xintercept = mean(height), color = "Mean"), size = 1.5) +
scale_color_manual(name = "Descriptive Statistics", values = c(Median = "red", Mean = "#eebf48")) +
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_bar <- height %>% group_by(sex) %>%
ggplot(aes(x = height)) + geom_bar(stat = "count", fill = "#a5d3c1", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_chart <- height %>% group_by(sex) %>%
summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Count" = n(),
"Standard Deviation" = sd(height))
total_height_sex_histogram <- height %>%
group_by(sex) %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram( aes(y = ..density..), col = "black", position = "dodge")+
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite), fill = "Sex")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men <- height %>% filter(sex == "M")
height_women <- height %>% filter(sex == "F")
height_men_hist <- height_men %>%
ggplot(aes(x = height)) + geom_histogram(aes(y = ..density..), fill = "blue", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_men$height), sd(height_men$height)),
col = "blue",
lwd = 1)
height_women_hist <- height_women %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram(aes(y = ..density..), fill = "#990000", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_women_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_women$height), sd(height_women$height)),
col = "black",
lwd = 1) +
labs(y = "Probability Distribution")
prob_57 <- pnorm(57, mean = mean(height_women$height), sd = sd(height_women$height))
prob_164 <- pnorm(164, mean = mean(height_women$height), sd = sd(height_women$height))
height_cm <- read_csv(file_location)
height_cm
height <- height_cm %>% select(height, sex)
height
height <- height[1] * 2.54
height
library("tidyverse")
#all heights in inches
cite <- "https://vincentarelbundock.github.io/Rdatasets/doc/carData/Davis.html"
#height <- read_csv("/Users/martin.gleason/Dropbox (Personal)/Coding Projects/DataSets/height_weight.csv") #windows version
file_location <- "/Users/marty/Dropbox (Personal)/Coding Projects/DataSets/height_weight.csv"
height_cm <- read_csv(file_location)
height <- height_cm %>% select(height, sex)
height[1] <- height[1] * 2.54
height_quants <- height %>% summarise(q5 = quantile(height, .05),
q95 = quantile(height, .95),
avg = mean(height),
median = median(height))
x.dens <- density(height$height)
df_height_den <- data.frame(x = x.dens$x, y = x.dens$y)
bad_height <- height %>% summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Standard Deviation, in Inches" = sd(height))
total_height <- height %>%
ggplot(aes(x = height)) +
geom_density(fill = "#a5d3c1") +
labs(x = "Height in Inches", y = "Probability Distribution")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
bad_proof <- total_height +
geom_area(data = subset(df_height_den, x >= height_quants$q5 & x <= height_quants$q95),
aes(x = x, y = y), fill = "#9b9292") +
geom_vline(aes(xintercept = height_quants$median, color = "Median"), size = 1.5) +
geom_vline(aes(xintercept = mean(height), color = "Mean"), size = 1.5) +
scale_color_manual(name = "Descriptive Statistics", values = c(Median = "red", Mean = "#eebf48")) +
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_bar <- height %>% group_by(sex) %>%
ggplot(aes(x = height)) + geom_bar(stat = "count", fill = "#a5d3c1", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
total_height_chart <- height %>% group_by(sex) %>%
summarize("Average Height" = mean(height),
"Median Height" = median(height),
"Shortest" = min(height),
"Tallest" = max(height),
"Count" = n(),
"Standard Deviation" = sd(height))
total_height_sex_histogram <- height %>%
group_by(sex) %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram( aes(y = ..density..), col = "black", position = "dodge")+
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite), fill = "Sex")+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men <- height %>% filter(sex == "M")
height_women <- height %>% filter(sex == "F")
height_men_hist <- height_men %>%
ggplot(aes(x = height)) + geom_histogram(aes(y = ..density..), fill = "blue", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_men_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_men$height), sd(height_men$height)),
col = "blue",
lwd = 1)
height_women_hist <- height_women %>%
ggplot(aes(x = height, fill = sex)) + geom_histogram(aes(y = ..density..), fill = "#990000", col = "black") +
labs(x = "Height in Inches", y = "Total at that Height", caption = paste("Data from: " , cite))+
theme(axis.text = element_text(family = "Nobile", size = 18 ),
axis.title = element_text(family = "Nobile", size = 17 ))
height_women_hist + stat_function(fun = dnorm,
args = list(mean = mean(height_women$height), sd(height_women$height)),
col = "black",
lwd = 1) +
labs(y = "Probability Distribution")
prob_57 <- pnorm(57, mean = mean(height_women$height), sd = sd(height_women$height))
prob_164 <- pnorm(164, mean = mean(height_women$height), sd = sd(height_women$height))
source("normal_height.R")
library("sysfonts")
source("normal_height.R")
install.packages(c("dbplyr", "Rcpp", "yaml"))
install.packages(c("dbplyr", "Rcpp", "yaml"))
install.packages(c("dbplyr", "Rcpp", "yaml"))
library("sysfonts")
install.packages("sysfonts")
install.packages("sysfonts")
library("showtext")
update.packages(checkBuilt = TRUE)
xaringan:::inf_mr()
words_tidy %>%
count(word) %>%
with(wordcloud(word, n, min.freq = 1,
max.words = 25, colors = pro_colors_scheme,
family = "Nobile",
scale = c(4, 1)),
fill = "transparent",
height = 960, width =960, units = "px")
?knit
xaringan:::inf_mr()
words_tidy %>%
count(word) %>%
with(wordcloud2(word, n, mn.freq = 1,
max.words = 25, colors = pro_colors_scheme,
family = "Nobile",
scale = c(4, 1)),
fill = "transparent")
xaringan:::inf_mr()
words_tidy %>%
count(word)
words_tidy %>%
count(word) %>%
with(wordcloud2(word, n,
color = pro_colors_scheme,
fontFamily = "Nobile",
backgroundColor = "transparent"))
xaringan:::inf_mr()
words_tidy %>%
count(word) %>%
wordcloud2(word,
color = pro_colors_scheme,
fontFamily = "Nobile",
backgroundColor = "transparent"
words_tidy %>%
words_tidy %>%
count(word) %>%
wordcloud2(word,
color = pro_colors_scheme,
fontFamily = "Nobile",
backgroundColor = "Transparent")
words_tidy %>%
count(word) %>%
wordcloud2(word,
color = pro_colors_scheme,
fontFamily = "Nobile",
backgroundColor = "Transparent")
words_tidy %>%
count(word) %>%
wordcloud2(word)
words_tidy %>%
count(word) %>%
wordcloud2(word)
words_tidy %>%
count(word) %>%
wordcloud2(word)
words_tidy %>%
count(word) %>%
wordcloud2()
words_tidy %>%
count(word) %>%
wordcloud2(color = pro_colors_scheme,
fontFamily = "Nobile",
backgroundColor = "Transparent")
words_tidy %>%
count(word) %>%
wordcloud2(color = pro_colors_scheme,
fontFamily = "Nobile",
backgroundColor = "Transparent")
pro_colors_scheme
pro_colors_scheme[2]
pro_colors_scheme
View(pro_colors_scheme)
View(pro_colors_scheme2)
words_tidy %>%
count(word) %>%
wordcloud2(color = pro_colors_scheme2,
fontFamily = "Nobile",
backgroundColor = "Transparent")
words_tidy %>%
count(word) %>%
wordcloud2(color = pro_colors_scheme2,
fontFamily = "Nobile",
backgroundColor = "Transparent",
shape = "cardiod")
words_tidy %>%
count(word) %>%
wordcloud2(color = pro_colors_scheme2,
fontFamily = "Nobile",
backgroundColor = "Transparent",
shape = "cardioid")
words_tidy %>%
count(word) %>%
wordcloud2(color = pro_colors_scheme2,
fontFamily = "Nobile",
backgroundColor = "Transparent",
shape = "cardioid")
words_tidy %>%
count(word) %>%
wordcloud2(color = pro_colors_scheme2,
fontFamily = "Nobile",
backgroundColor = "Transparent",
shape = "triangle")
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
<<<<<<< HEAD
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
## Court data/statistics wordcloud
library("tidyverse")
library("googlesheets")
library("wordcloud")
library("wordcloud2")
library("RColorBrewer")
library("sysfonts")
library("tidytext")
library("showtext")
font_add_google(name = "Nobile")
source("../scripts/color_scheme.R")
responses <- gs_url("https://docs.google.com/spreadsheets/d/1oqOAeku8K8JGb31U8HGHu6PsAaxGWdtFxZFLUKtDlpE/edit#gid=1115118292")
sheet <- gs_read(responses)
email <- sheet$`Email Address`
length(unique(email))
words_untidy <- sheet[7]
names(words_untidy) <- "text"
words_tidy <- words_untidy %>%
unnest_tokens(word, text) %>%
anti_join(get_stopwords())
question_cloud <- words_tidy %>%
=======
png(color = "transparent", height = 1200, width =1200)
?png
with(png(color = "transparent", height = 1200, width =1200))
with(png("registrationcloud", color = "transparent", height = 1200, width =1200))
with(png("registrationcloud.png", color = "transparent", height = 1200, width =1200))
words_tidy %>%
>>>>>>> master
count(word) %>%
with(wordcloud(word, n, min.freq = 1,
max.words = 25, colors = pro_colors_scheme,
family = "Nobile",
scale = c(4, 1)),
<<<<<<< HEAD
fill = "transparent")
wc2 <- words_tidy %>%
count(word) %>%
wordcloud2(fontFamily = "Nobile", color = pro_colors_scheme2, size = 1)
class(wc2)
plot(wc2)
wc2
?wordcloud2
source('~/Dropbox (Personal)/Coding Projects/R/data_literacy101/wordcloud.R')
wc2 <- words_tidy %>%
count(word) %>%
wordcloud2(fontFamily = "Nobile",
color = pro_colors_scheme2,
backgroundColor = "transparent",
size = 1)
wc2
words_tidy %>% count(word)
source('~/Dropbox (Personal)/Coding Projects/R/data_literacy101/wordcloud.R')
wc2 <- words_tidy %>%
count(word) %>%
arrange(desc()) %>%
wordcloud2(fontFamily = "Nobile",
color = pro_colors_scheme2,
backgroundColor = "transparent",
size = 1)
words_tidy %>%
count(word) %>%
arrange(desc())
words_tidy %>%
count(word) %>%
arrange() %>%
words_tidy %>%
count(word) %>%
arrange() %>%
words_tidy %>%
count(word) %>%
arrange()
words_tidy <- words_untidy %>%
unnest_tokens(word, text) %>%
anti_join(get_stopwords())
words_tidy %>%
count(word) %>%
arrange()
words_tidy %>%
count(word) %>%
arrange(desc())
words_tidy %>%
count(word) %>%
arrange(desc) %>%
words_tidy %>%
count(word) %>%
arrange(desc)
?arrange
words_tidy %>%
count(word) %>%
arrange(desc(n))
source('~/Dropbox (Personal)/Coding Projects/R/data_literacy101/wordcloud.R')
wc2 <- words_tidy %>%
count(word) %>%
arrange(desc(n)) %>%
wordcloud2(fontFamily = "Nobile",
color = pro_colors_scheme2,
backgroundColor = "transparent",
size = 1)
wc2
source('~/Dropbox (Personal)/Coding Projects/R/data_literacy101/wordcloud.R')
source('~/Dropbox (Personal)/Coding Projects/R/data_literacy101/wordcloud.R')
xaringan:::inf_mr()
=======
fill = "transparent",
height = 1200, width =1200)
words_tidy %>%
count(word) %>%
with(wordcloud(word, n, min.freq = 1,
max.words = 25, colors = pro_colors_scheme,
family = "Nobile",
scale = c(4, 1)),
fill = "transparent")
png(height = 1200, width =1200)
par(mar = rep(0, 4))
words_tidy %>%
count(word) %>%
with(wordcloud(word, n, min.freq = 1,
max.words = 25, colors = pro_colors_scheme,
family = "Nobile",
scale = c(4, 1)),
fill = "transparent")
#png(height = 1200, width =1200)
par(mar = rep(0, 4))
?png
?par
?plot
words_tidy %>%
count(word) %>%
with(wordcloud(word, n, min.freq = 1,
max.words = 25, colors = pro_colors_scheme,
family = "Nobile",
scale = c(4, 1)),
fill = "transparent")
png("registration_cloud", height = 960, width = 960, bg = "transparent")
words_tidy %>%
count(word) %>%
with(wordcloud(word, n, min.freq = 1,
max.words = 25, colors = pro_colors_scheme,
family = "Nobile",
scale = c(4, 1)),
fill = "transparent")
dev.off()
source("wordcloud.R")
words_tidy %>%
count(word) %>%
wordcloud2(color = pro_colors_scheme2,
size = 1,
gridSize = 1,
fontFamily = "Nobile",
backgroundColor = "Transparent",
shape = "triangle")
#out.extra='style="display:block;"'
View(words_tidy)
>>>>>>> master
